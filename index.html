<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="google-site-verification" content="tHWkCv5kReG-fq--FCW61agzVOiLPlJyOQ_-2OEmgy8" />

  <title>Li MA</title>
  <meta name="description"
        content="The homepage of MA Li">
  <meta name="keywords" content="Li MA, MA Li, homepage, github, website">
  <meta name="author" content="MA Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Li MA È©¨Âäõ</name>
              </p>
              <p>
                I'm currently a Research Scientist at <a href="https://www.scanlinevfx.com">Scanline VFX Studio</a> working with <a href="https://www.pauldebevec.com">Paul Debevec</a>.
                I obtained my PhD from the Dept. of Computer Science & Engineering
                in the Hong Kong University of Science and Technology (<a href="https://hkust.edu.hk/">HKUST</a>).
                My PhD advisor is <a href="https://www.cse.ust.hk/~psander/">Prof. Pedro V. SANDER</a>, 
                and I worked closely with <a href="https://liaojing.github.io/html/">Prof. Liao Jing</a>.
                Before that, I received my Bachelor's Degree in EE from Zhejiang University in 2019.
              </p>
              
              <p> I was a research intern at Meta Reality Labs from May to October 2023, with <a href="https://zollhoefer.com">Michael Zollhoefer</a> and <a href="https://richardt.name">Christian Richardt</a> as my managers.
                Previously, I was a research intern at Tencent AI Lab under the guidance of <a href="https://xiaoyu258.github.io">Xiaoyu Li</a> from August 2021 to September 2022. 
              </p>
              
              <p>I'm interested in Novel View Synthesis, Neural Rendering, 
                Differentiable Rendering, and other graphics-related vision topics.
              </p>
              
              <p>
                Before I delve into neural rendering research, I've also engaged in some low-level image and video processing tasks, 
                including image/video stitching, inpainting, HDR creation, style transfer, video stabilization, and optical flow estimation. 
              </p>

              <p style="text-align:center">
                <a href="mailto:lmaag@connect.ust.hk">Email</a> &nbsp/&nbsp
                <a href="https://github.com/limacv">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=veS098oAAAAJ&hl=en&oi=sra">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/maleewahaha">Twitter</a> &nbsp/&nbsp
                <a href="linkedin.com/in/maa-lee-a27b27247">LinkedIn</a> &nbsp/&nbsp
                <a href="data/LiMa_CV.pdf">CV</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/mali.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/mali_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>News</heading>
              <br><br>
              <li>COMP5411 Advanced Computer Graphics, 2022-23 Fall </li>
              <li>COMP5411 Advanced Computer Graphics, 2020-21 Fall</li>
              <li>COMP2011 Programming with C++, 2019-20 Spring </li>
            </td>
          </tr>
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                Representative papers are <span class="highlight">highlighted</span>. * indicates equal contribution.
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					
          <!-- ########################################################### -->
          <tr onmouseout="luxpostfacto_stop()" onmouseover="luxpostfacto_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="overflow: hidden;">
              <video  width=200% height=200% 
                      muted autoplay loop id="luxpostfacto"
                      style="position: absolute; left: -100%; top: -50%">
                <source src="images/luxpostfactovid.mp4" type="video/mp4">
              </video>
              </div>
              <script type="text/javascript">
                function luxpostfacto_start() {
                  document.getElementById('luxpostfacto').style.left = "-100%";
                }

                function luxpostfacto_stop() {
                  document.getElementById('luxpostfacto').style.left = "0%";
                }
                luxpostfacto_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Lux Post Facto: Learning Portrait Performance Relighting with Conditional Video Diffusion and a Hybrid Dataset</papertitle>
              <br>
              <a href="https://yiqunmei.net//">Yiqun Mei</a>,
              <a href="https://mingminghe.com/">Mingming He</a>,
              <strong>Li Ma</strong>,
              <a href="https://julienphilip.com/">Julien Philip</a>,
              <a href="https://www.cs.cornell.edu/~wenqixian/">Wenqi Xian</a>,
              <a href="https://www.linkedin.com/in/david-george-90703-ca">David M George</a>,
              <a href="mailto:xueming.yu@scanlinevfx.com">Xueming Yu</a>,
              <a href="https://www.linkedin.com/in/gabrield/">Gabriel Dedic</a>,
							<a href="https://leventtasel.com/">Ahmet Levent Ta≈üel</a>,
              <a href="https://ningyu1991.github.io/">Ning Yu</a>,
              <a href="https://engineering.jhu.edu/faculty/vishal-patel/">Vishal M. Patel</a>,
              <a href="https://www.pauldebevec.com/Bio/">Paul Debevec</a>
              <br>
              <em>CVPR</em>, 2025
              <br>
              <a href="https://www.eyelinestudios.com/research/luxpostfacto.html">project page</a>
              /
              <a href="https://arxiv.org/abs/2503.14485">arXiv</a>
              /
              <a href="https://www.eyelinestudios.com/research/luxpostfacto_static/pdfs/lux_post_facto.pdf">pdf</a>
              <p></p>
              <p>
              A generalizable portrait video relighting method that produces both photorealistic and temporally consistent lighting effects.
              </p>
            </td>
          </tr>
          
          
          <!-- ########################################################### -->
          <tr onmouseout="gowiththeflow_stop()" onmouseover="gowiththeflow_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="overflow: hidden;">
              <video  width=200% height=200% 
                      muted autoplay loop id="gowiththeflow"
                      style="position: absolute; left: -100%; top: -50%">
                <source src="images/gowiththeflowvid.mov" type="video/mp4">
              </video>
              </div>
              <script type="text/javascript">
                function gowiththeflow_start() {
                  document.getElementById('gowiththeflow').style.left = "-100%";
                }

                function gowiththeflow_stop() {
                  document.getElementById('gowiththeflow').style.left = "0%";
                }
                gowiththeflow_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise</papertitle>
              <br>
              <a href="https://ryanndagreat.github.io/">Ryan Burgert</a>,
              <a href="https://yuancheng-xu.github.io/">Yuancheng Xu</a>,
              <a href="https://www.cs.cornell.edu/~wenqixian/">Wenqi Xian</a>,
              <a href="mailto:oliver.pilarski@scanlinevfx.com">Oliver Pilarski</a>,
              <a href="mailto:pascal.clausen@scanlinevfx.com">Pascal Clausen</a>,
              <a href="https://mingminghe.com/">Mingming He</a>,
              <strong>Li Ma</strong>,
              <a href="https://yitongdeng.github.io/">Yitong Deng</a>,
              <a href="https://scholar.google.com/citations?user=rxQDLWcAAAAJ&hl=en">Lingxiao Li</a>,
              <a href="https://www.imdb.com/name/nm2417929/">Mohsen Mousavi</a>,
              <a href="http://michaelryoo.com/">Michael Ryoo</a>,
              <a href="https://www.pauldebevec.com/Bio/">Paul Debevec</a>,
              <a href="https://ningyu1991.github.io/">Ning Yu</a>
              <br>
              <em>CVPR</em>, 2025 <a style="color:red;">(Oral)</a>
              <br>
              <a href="https://eyeline-labs.github.io/Go-with-the-Flow/">project page</a>
              /
              <a href="https://arxiv.org/abs/2501.08331">arXiv</a>
              /
              <a href="https://github.com/Eyeline-Research/Go-with-the-Flow">github</a>
              <p></p>
              <p>
              Fine-tuning a video model using warped nosie allows for motion control!
              </p>
            </td>
          </tr>

          <!-- ########################################################### -->
          <tr onmouseout="diffrelit_stop()" onmouseover="diffrelit_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="overflow: hidden;">
              <video  width=200% height=200% 
                      muted autoplay loop id="diffrelit"
                      style="position: absolute; left: -100%; top: -50%">
                <source src="images/diffrelit.mov" type="video/mp4">
              </video>
              </div>
              <script type="text/javascript">
                function diffrelit_start() {
                  document.getElementById('diffrelit').style.left = "0%";
                }

                function diffrelit_stop() {
                  document.getElementById('diffrelit').style.left = "-100%";
                }
                diffrelit_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>DifFRelight: Diffusion-Based Facial Performance Relighting</papertitle>
              <br>
              <a href="https://mingminghe.com/">Mingming He*</a>,
              <a href="mailto:pascal.clausen@scanlinevfx.com">Pascal Clausen*</a>,
							<a href="https://leventtasel.com/">Ahmet Levent Ta≈üel*</a>,
              <strong>Li Ma*</strong>,
              <a href="mailto:oliver.pilarski@scanlinevfx.com">Oliver Pilarski*</a>,
              <a href="https://www.cs.cornell.edu/~wenqixian/">Wenqi Xian</a>,
              <a href="mailto:laszlo.rikker@scanlinevfx.com">Laszlo Rikker</a>,
              <a href="mailto:xueming.yu@scanlinevfx.com">Xueming Yu</a>,
              <a href="https://ryanndagreat.github.io/">Ryan Burgert</a>,
              <a href="https://ningyu1991.github.io/">Ning Yu</a>,
              <a href="https://www.pauldebevec.com/Bio/">Paul Debevec</a>
              <br>
              <em>Siggraph Asia</em>, 2024
              <br>
              <a href="https://www.eyelinestudios.com/research/diffrelight.html">project page</a>
              /
              <a href="https://arxiv.org/abs/2410.08188">arXiv</a>
              /
              <a href="https://www.eyelinestudios.com/research/diffrelight_static/pdfs/diffrelight.pdf">pdf</a>
              <p></p>
              <p>
              A personalized diffusion-based relighting model that achieves photorealistic facial performance relighting.
              </p>
            </td>
          </tr>
          

          <!-- ########################################################### -->
          <tr onmouseout="fisheyegs_stop()" onmouseover="fisheyegs_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='fisheyegs'>
                <img src='images/fisheyegs_fisheye.jpeg' width="160"></div>
              <!-- <div class="two" id='dreamfusion_image'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/dreamfusion.mp4" type="video/mp4">Your browser does not support the video tag.
                </video></div> -->
              <img src='images/fisheyegs_presp.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function fisheyegs_start() {
                  document.getElementById('fisheyegs').style.opacity = "1";
                }

                function fisheyegs_stop() {
                  document.getElementById('fisheyegs').style.opacity = "0";
                }
                fisheyegs_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Fisheye-GS: Lightweight and Extensible Gaussian Splatting Module for Fisheye Cameras</papertitle>
              <br>
              <a href="https://zmliao.github.io">Zimu Liao</a>,
              Siyan Chen, Rong Fu, Yi Wang, Zhongling Su, Hao Luo, 
              <strong>Li Ma</strong>,
              <a href="https://eveneveno.github.io/lnxu/">Linning Xu</a>,
              <a href="https://daibo.info/">Bo Dai</a>, 
              Hengjie Li, Zhilin Pei, Xingcheng Zhan
              <br>
              <em>ECCVW</em>, 2024
              <br>
              <a href="https://github.com/zmliao/Fisheye-GS">project page & code</a>
              /
              <a href="https://arxiv.org/abs/2409.04751">arXiv</a>
              <p></p>
              <p>
                Extending Gaussian Splatting to fisheye camera model, with both forward rendering and backward propagation.
              </p>
            </td>
          </tr>
          

          <!-- ########################################################### -->
          <tr onmouseout="specnerf_stop()" onmouseover="specnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='specnerf'>
                <img src='images/SpecNeRF_ns.png' width="160"></div>
              <!-- <div class="two" id='dreamfusion_image'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/dreamfusion.mp4" type="video/mp4">Your browser does not support the video tag.
                </video></div> -->
              <img src='images/specNeRF_rgb.png' width="160">
              </div>
              <script type="text/javascript">
                function specnerf_start() {
                  document.getElementById('specnerf').style.opacity = "1";
                }

                function specnerf_stop() {
                  document.getElementById('specnerf').style.opacity = "0";
                }
                specnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SpecNeRF: Gaussian Directional Encoding for Specular Reflections</papertitle>
              <br>
              <strong>Li Ma</strong>,
              <a href="https://notes.vasuagrawal.com/">Vasu Agrawal</a>,
              <a href="https://haithemturki.com/">Haithem Turki</a>,
              <a href="https://changilkim.com">Changil Kim</a>,
							<a href="https://www.chengao.vision/">Chen Gao</a>,
              <a href="https://www.cse.ust.hk/~psander/">Pedro V. Sander</a>,
              <a href="https://zollhoefer.com/">Michael Zollh√∂fer</a>, 
              <a href="https://richardt.name/">Christian Richardt</a>
              <br>
              <em>CVPR</em>, 2024 <a style="color:red;">(highlight)</a>
              <br>
              <a href="https://limacv.github.io/SpecNeRF_web/">project page</a>
              /
              <a href="https://arxiv.org/abs/2312.13102">arXiv</a>
              /
              <a href="https://limacv.github.io/SpecNeRF_web/images/SpecNeRF.pdf">pdf</a>
              <p></p>
              <p>
                We propose a Gaussian directional encoding that leads to better modeling of specular reflections under near-field lighting conditions.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="loop3d_stop()" onmouseover="loop3d_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='loop3d'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/loop3d_spiral.mov" type="video/mp4">Your browser does not support the video tag.
                </video></div>
              <video width=100% height=100% muted autoplay loop id="loop3d1">
                <source src="images/loop3d.mov" type="video/mp4">Your browser does not support the video tag.
              </video>
              </div>
              <script type="text/javascript">
                function loop3d_start() {
                  document.getElementById('loop3d').style.display = '';
                  document.getElementById('loop3d1').style.display = 'none'
                }

                function loop3d_stop() {
                  document.getElementById('loop3d').style.display = 'none';
                  document.getElementById('loop3d1').style.display = ''
                }
                loop3d_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>3D Video Loops from Asynchronous Input</papertitle>
              <br>
              <strong>Li Ma</strong>,
              <a href="https://xiaoyu258.github.io/">Xiaoyu Li</a>,
              <a href="https://liaojing.github.io/html/">Jing Liao</a>,
              <a href="https://www.cse.ust.hk/~psander/">Pedro V. Sander</a>
              <br>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://limacv.github.io/VideoLoop3D_web/">project page</a>
              /
              <a href="https://limacv.github.io/VideoLoopUI/">live demo</a> (<a href=https://limacv.github.io/VideoLoopUI/?use_vr>VR demo</a>)
              /
              <a href="https://arxiv.org/abs/2303.05312">Arxiv</a>
              /
              <a href="https://limacv.github.io/VideoLoop3D_web/images/CVPR2023.pdf">pdf</a>
              /
              <a href="https://github.com/limacv/VideoLoop3D">code</a>
              <p></p>
              <p>
              We construct a novel 3D looping video representation that can do novel view synthesis in real-time on an iPhone X!
              </p>
              <p>
                <strong>Apr. 2023 update:</strong> we add VR support to the live demo! (see the VR demo above)
              </p>
            </td>
          </tr>
      

          <tr onmouseout="nep_stop()" onmouseover="nep_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="overflow: hidden;">
                <video  width=200% height=200% 
                        muted autoplay loop id="nep"
                        style="position: absolute; left: -100%; top: -50%">
                  <source src="images/nep.mov" type="video/mp4">
                </video>
              </div>
              <script type="text/javascript">
                function nep_start() {
                  document.getElementById('nep').style.left = "0%";
                }

                function nep_stop() {
                  document.getElementById('nep').style.left = "-100%";
                }
                nep_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Neural Parameterization for Dynamic Human Head Editing</papertitle>
              <br>
              <strong>Li Ma</strong>,
              <a href="https://xiaoyu258.github.io/">Xiaoyu Li</a>,
              <a href="https://liaojing.github.io/html/">Jing Liao</a>,
							<a href="https://xuanwangvc.github.io/">Xuan Wang</a>,
              <a href="https://qzhang-cv.github.io">Qi Zhang</a>,
              <a href="https://juewang725.github.io/">Jue Wang</a>,
              <a href="https://www.cse.ust.hk/~psander/">Pedro V. Sander</a>
              <br>
              <em>Siggraph Asia</em>, 2022
              <br>
              <a href="https://limacv.github.io/neuvf_web/">project page</a>
              /
              <a href="https://arxiv.org/abs/2207.00210">arXiv</a>
              /
              <a href="https://limacv.github.io/neuvf_web/pdf/SIGGRAPH2022_Final.pdf">pdf</a>
              /
              <a href="https://github.com/limacv/NeUVF">code</a>
              <p></p>
              <p>
              We try to introduce explicit parameters into implicit dynamic NeRF representations to achieve editing of 3D human heads.
              </p>
            </td>
          </tr>
          

          <tr onmouseout="deblurnerf_stop()" onmouseover="deblurnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='deblurnerf'>
                <img src='images/deblurnerf_out.png' width="160"></div>
              <!-- <div class="two" id='dreamfusion_image'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/dreamfusion.mp4" type="video/mp4">Your browser does not support the video tag.
                </video></div> -->
              <img src='images/deblurnerf_in.png' width="160">
              </div>
              <script type="text/javascript">
                function deblurnerf_start() {
                  document.getElementById('deblurnerf').style.opacity = "1";
                }

                function deblurnerf_stop() {
                  document.getElementById('deblurnerf').style.opacity = "0";
                }
                deblurnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Deblur-NeRF: Neural Radiance Fields from Blurry Images</papertitle>
              <br>
              <strong>Li Ma</strong>,
              <a href="https://xiaoyu258.github.io/">Xiaoyu Li</a>,
              <a href="https://liaojing.github.io/html/">Jing Liao</a>,
              <a href="https://qzhang-cv.github.io">Qi Zhang</a>,
							<a href="https://xuanwangvc.github.io/">Xuan Wang</a>,
              <a href="https://juewang725.github.io/">Jue Wang</a>,
              <a href="https://www.cse.ust.hk/~psander/">Pedro V. Sander</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://limacv.github.io/deblurnerf/">project page</a>
              /
              <a href="https://arxiv.org/abs/2111.14292">arXiv</a>
              /
              <a href="https://limacv.github.io/deblurnerf/pdf/CVPR2022_DeblurNeRF.pdf">pdf</a>
              /
              <a href="https://github.com/limacv/Deblur-NeRF">code</a>
              <p></p>
              <p>
              We optimize a NeRF and the blur kernels jointly from multi-view blurry images to get a sharp NeRF.
              </p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <img src='images/tvconv.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>TVConv: Efficient Translation Variant Convolution</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=8rPHNOsAAAAJ">Jierun Chen</a>,
              <a href="https://scholar.google.com/citations?user=DJ3nT1kAAAAJ">Tianlang He</a>,
              <a href="https://scholar.google.com/citations?user=DeufvEIAAAAJ">Weipeng Zhuo</a>,
              <strong>Li Ma</strong>,
							<a href="http://netstech.org/sangtaeha/">Sangtae Ha</a>,
              <a href="http://home.cse.ust.hk/~gchan/">S.-H. Gary Chan</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2203.10489">arXiv</a>
              /
              <a href="https://github.com/JierunChen/TVConv">code</a>
              <p></p>
              <p>
              We overparameterize a weight-generating block during training for efficient inference of dynamic convolutions.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="automatch_stop()" onmouseover="automatch_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='automatch'>
                <img src='images/automatch_after.jpg' width="160"></div>
              <img src='images/automatch.jpg' width="160">
              </div>
              <script type="text/javascript">
                function automatch_start() {
                  document.getElementById('automatch').style.opacity = "1";
                }

                function automatch_stop() {
                  document.getElementById('automatch').style.opacity = "0";
                }
                automatch_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>AutoMatch: Leveraging Traffic Camera to Improve Perception and Localization of Autonomous Vehicles</papertitle>
              <br>
              <a href="https://yuzehh.github.io/homepage/">Yuze He</a>,
              <strong>Li Ma</strong>,
              Jiahe Cui,
              Zhenyu Yan,
              <a href="https://staff.ie.cuhk.edu.hk/~glxing/">Guoliang Xing</a>,
              Sen Wang,
              Qintao Hu,
              Chen Pan
              <br>
              <em>SenSys</em>, 2022
              <br>
              <a href="https://mycuhk-my.sharepoint.com/:b:/g/personal/1155136636_link_cuhk_edu_hk/EZINmTbc9SFLr-XtkNxZInYBmnhcmlz4cI8NUZC81uWQIA?e=TUDVDV">pdf</a>
              /
              <a href="https://mycuhk-my.sharepoint.com/:p:/g/personal/1155136636_link_cuhk_edu_hk/EfL9MUWNeaROphkbj08yNCsBpQvCtwMKUm6vEIpf6wkuSg?e=3amfUr">slides</a>
              <p></p>
              <p>
                We exploit existing ubiquitous traffic cameras to assist perception and localization in autonomous driving.
              </p>
            </td>
          </tr>


          <tr onmouseout="vieye_stop()" onmouseover="vieye_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
              <div class="two" id='vieye'>
                <img src='images/vieye_after.png' width="160"></div>
              <img src='images/vieye_before.png' width="160">
              </div>
              <script type="text/javascript">
                function vieye_start() {
                  document.getElementById('vieye').style.opacity = "1";
                }

                function vieye_stop() {
                  document.getElementById('vieye').style.opacity = "0";
                }
                vieye_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>VI-Eye: Semantic-based 3D Point Cloud Registration for
                          Infrastructure-assisted Autonomous Driving</papertitle>
              <br>
              <a href="https://yuzehh.github.io/homepage/">Yuze He</a>,
              <strong>Li Ma</strong>,
              Zhehao Jiang,
              Yi Tang,
							<a href="https://staff.ie.cuhk.edu.hk/~glxing/">Guoliang Xing</a>
              <br>
              <em>MobiCom</em>, 2021
              <br>
              <a href="https://dl.acm.org/doi/10.1145/3447993.3483276">pdf</a>
              /
              <a href="https://www.youtube.com/watch?v=IYu8d8Rzy2s">fast forward</a>
              /
              <a href="https://mycuhk-my.sharepoint.com/:v:/g/personal/1155136636_link_cuhk_edu_hk/EfS9bjWA58lDrShdRe8cCbQB9RpNnKUpCuf5QvO0piAhAA?e=rjZMFn">presentation</a>
              /
              <a href="https://mycuhk-my.sharepoint.com/:p:/g/personal/1155136636_link_cuhk_edu_hk/EfUXpfbzIF1NkyEh4eLvO0gBWCENv2DhRIVdp6Q88rtVYA?e=3Uux6F">slides</a>
              <p></p>
              <p>
              We align two point clouds with little overlap using saliency points in the traffic scenario.
              </p>
            </td>
          </tr>
          
        </tbody></table>
        
				<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Other Projects</heading>
            <p>
              Some interesting projects that I worked on, including research projects.
            </p>
          </td>
        </tr>
      </tbody></table>
      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr onmouseout="replate_stop()" onmouseover="replate_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='images/gs_viewer.jpeg' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>3D Gaussian Splatting Viewer</papertitle>
            <br>
              <em>Toy Project</em>, 2023
            <br>
            <br>
            <a href="https://github.com/limacv/GaussianSplattingViewer">code</a>
            <p></p>
            <p>
            A PyOpenGL based 3D Gaussian Splatting Viewer.
            </p>
            <p>
              <strong>Dec. 2023 update:</strong> The viewer now supports CUDA backend! It's useful for debugging the official CUDA rasterizer.
            </p>
          </td>
        </tr>

        <tr onmouseout="replate_stop()" onmouseover="replate_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
            <div class="two" id='replate'>
              <video  width=100% height=100% muted autoplay loop>
                <source src="images/replate.mov" type="video/mp4">Your browser does not support the video tag.
              </video></div>
            <img src='images/replate.jpg' width="160">
            </div>
            <script type="text/javascript">
              function replate_start() {
                document.getElementById('replate').style.opacity = "1";
              }

              function replate_stop() {
                document.getElementById('replate').style.opacity = "0";
              }
              replate_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>The Replate</papertitle>
            <br>
            <strong>Li Ma</strong>,
            Ge Chen,
            <a href="https://www.cse.ust.hk/~psander/">Pedro V. Sander</a>
            <br>
              <em>Funded Project</em>, 2021
            <br>
            <a href="https://limacv.github.io/ReplateWidget/">project page</a>
            /
            <a href="https://github.com/limacv/ReplateWidget">code</a>
            <p></p>
            <p>
            A Qt-based software that allows you to create infinitely looping videos from sports videos.
            </p>
          </td>
        </tr>
        
        <tr onmouseout="monompv_stop()" onmouseover="monompv_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='monompv'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/lmpv.mov" type="video/mp4">Your browser does not support the video tag.
                </video></div>
              <img src='images/lmpv.jpg' width="160">
              </div>
              <script type="text/javascript">
                function monompv_start() {
                  document.getElementById('monompv').style.opacity = "1";
                }
  
                function monompv_stop() {
                  document.getElementById('monompv').style.opacity = "0";
                }
                monompv_stop()
              </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Layered Multiplane Videos for Novel View Synthesis</papertitle>
            <br>
              <strong>Li Ma</strong>,
              <a href="https://liaojing.github.io/html/">Jing Liao</a>,
              <a href="https://www.cse.ust.hk/~psander/">Pedro V. Sander</a>
            <br>
              <em>Research Project</em>, 2021
            <br>
            <a href="https://limacv.github.io/mono_mpv/">project page</a>
            /
            <a href="https://limacv.github.io/mono_mpv/pdf/ICCV21.pdf">pdf</a>
            /
            <a href="https://limacv.github.io/mono_mpv/pdf/ICCV21_supple.pdf">supple</a>
            /
            <a href="https://github.com/limacv/mono_mpv">code</a>
            <p></p>
            <p>
            We try to generate a temporally consistent Multiplane Video (MPV) from only monocular video 
            to achieve space and time control. The results are actually not as good as expected.
            But still, I post this project as a constant reminder for me to evaluate the feasibility before expending too much effort.
            </p>
          </td>
        </tr>

        <tr onmouseout="boolgeo_stop()" onmouseover="boolgeo_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='boolgeo'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/boolgeo.mov" type="video/mp4">Your browser does not support the video tag.
                </video></div>
              <img src='images/boolgeo.jpg' width="160">
              </div>
              <script type="text/javascript">
                function boolgeo_start() {
                  document.getElementById('boolgeo').style.opacity = "1";
                }
  
                function boolgeo_stop() {
                  document.getElementById('boolgeo').style.opacity = "0";
                }
                boolgeo_stop()
              </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Boolean Text Geometry</papertitle>
            <br>
            <strong>Li Ma</strong>
            <br>
              <em>Course Project</em>, 2020
            <br>
            <a href="https://limacv.github.io/bool_geo_project/">live demo</a>
            /
            <a href="https://github.com/limacv/bool_geo_project">code</a>
            <p></p>
            <p>
            An interesting toy project based on Threejs that renders geometries that looks like different texts from different views.
            </p>
          </td>
        </tr>
      
        <tr onmouseout="car_stop()" onmouseover="car_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='car'>
                <video  width=100% height=100% muted autoplay loop>
                  <source src="images/car.mov" type="video/mp4">Your browser does not support the video tag.
                </video></div>
              <img src='images/car.jpg' width="160">
              </div>
              <script type="text/javascript">
                function car_start() {
                  document.getElementById('car').style.opacity = "1";
                }
  
                function car_stop() {
                  document.getElementById('car').style.opacity = "0";
                }
                car_stop()
              </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Intelligent Car Racing</papertitle>
            <br>
            Kai Wang*, <strong>Li Ma*</strong>, 
            <a href="https://yuzehh.github.io/homepage/">Yuze He*</a>
            <br>
              <em>The NXP Cup</em>, 2018
            <br>
            <a href="data/video1.MOV">video (group round)</a>
            /
            <a href="data/video(finals).MOV">video (finals)</a>
            <p></p>
            <p>
            Exciting car racing!
            </p>
          </td>
        </tr>


      </tbody></table>
      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching Assistant</heading>
              <br><br>
              <li>COMP5411 Advanced Computer Graphics, 2022-23 Fall </li>
              <li>COMP5411 Advanced Computer Graphics, 2020-21 Fall</li>
              <li>COMP2011 Programming with C++, 2019-20 Spring </li>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Professional Activities</heading>
              <br><br>
              <p>
                Reviewer for Siggraph Asia 2024, CVPR 2024, TOG, ECCV 2024, Siggraph 2024, PR, TMM, TPAMI, WACV 2024, ICCV 2023, CVPR 2023, BMVC 2021.
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Awards</heading>
              <br><br>
              <li>Postgraduate Scholarship, HKUST</li>
              <li>First-Class Scholarship for Outstanding Merits, ZJU </li>
              <li>First-Prize of the NXP Cup National University Students Intelligent Car Race (Zhejiang Division), China</li>
              <li>Second-Prize of the NXP Cup National University Students Intelligent Car Race, China</li>
              <li>Excellent Student Awards, ZJU </li>
              <li>Research and Innovation Scholarship, ZJU</li>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p style="text-align:center;font-size:small;">
                Thanks to <a href="http://jonbarron.info">Jon Barron</a> for sharing
                the <a href="https://github.com/jonbarron/jonbarron_website">source code</a> of his personal webpage.
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table>
            <div style="width:20%;margin:0 auto;">
              <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=iHv3_lG2sPiCA_ZhOlZUbBWq8UsaDqV2MTUO58ufGVQ&cl=ffffff&w=a">
              </script>
            </div>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>
